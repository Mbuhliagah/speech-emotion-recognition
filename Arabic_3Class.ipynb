{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/ANAD_Normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1383, 847)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Type</th>\n",
       "      <th>pcm_intensity_sma_max</th>\n",
       "      <th>pcm_intensity_sma_min</th>\n",
       "      <th>pcm_intensity_sma_range</th>\n",
       "      <th>pcm_intensity_sma_maxPos</th>\n",
       "      <th>pcm_intensity_sma_minPos</th>\n",
       "      <th>pcm_intensity_sma_amean</th>\n",
       "      <th>pcm_intensity_sma_linregc1</th>\n",
       "      <th>...</th>\n",
       "      <th>F0env_sma_de_linregerrQ</th>\n",
       "      <th>F0env_sma_de_stddev</th>\n",
       "      <th>F0env_sma_de_skewness</th>\n",
       "      <th>F0env_sma_de_kurtosis</th>\n",
       "      <th>F0env_sma_de_quartile1</th>\n",
       "      <th>F0env_sma_de_quartile2</th>\n",
       "      <th>F0env_sma_de_quartile3</th>\n",
       "      <th>F0env_sma_de_iqr12</th>\n",
       "      <th>F0env_sma_de_iqr23</th>\n",
       "      <th>F0env_sma_de_iqr13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>V2_1 (1).wav'</td>\n",
       "      <td>surprised</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092117</td>\n",
       "      <td>0.294281</td>\n",
       "      <td>0.771490</td>\n",
       "      <td>0.589508</td>\n",
       "      <td>0.117983</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.067167</td>\n",
       "      <td>2.028063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>V2_1 (2).wav'</td>\n",
       "      <td>surprised</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>0.203679</td>\n",
       "      <td>0.565664</td>\n",
       "      <td>0.335376</td>\n",
       "      <td>0.120382</td>\n",
       "      <td>0.027347</td>\n",
       "      <td>0.045084</td>\n",
       "      <td>0.044086</td>\n",
       "      <td>0.085771</td>\n",
       "      <td>3.003057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>V2_1 (3).wav'</td>\n",
       "      <td>surprised</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097341</td>\n",
       "      <td>0.341096</td>\n",
       "      <td>0.657804</td>\n",
       "      <td>0.451624</td>\n",
       "      <td>0.107132</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>0.067393</td>\n",
       "      <td>2.663894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>V2_1 (4).wav'</td>\n",
       "      <td>surprised</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055432</td>\n",
       "      <td>0.245241</td>\n",
       "      <td>0.516015</td>\n",
       "      <td>0.350308</td>\n",
       "      <td>0.121571</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>0.048233</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>3.138976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>V2_1 (5).wav'</td>\n",
       "      <td>surprised</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033673</td>\n",
       "      <td>0.199890</td>\n",
       "      <td>0.519454</td>\n",
       "      <td>0.265627</td>\n",
       "      <td>0.119747</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.045822</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>0.097964</td>\n",
       "      <td>3.087905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 847 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name   Emotion   Type  pcm_intensity_sma_max  \\\n",
       "0  V2_1 (1).wav'  surprised     2               0.285714   \n",
       "1  V2_1 (2).wav'  surprised     2               0.285714   \n",
       "2  V2_1 (3).wav'  surprised     2               0.285714   \n",
       "3  V2_1 (4).wav'  surprised     2               0.285714   \n",
       "4  V2_1 (5).wav'  surprised     2               0.142857   \n",
       "\n",
       "   pcm_intensity_sma_min  pcm_intensity_sma_range  pcm_intensity_sma_maxPos  \\\n",
       "0                      0                 0.285714                  0.414894   \n",
       "1                      0                 0.285714                  0.404255   \n",
       "2                      0                 0.285714                  0.404255   \n",
       "3                      0                 0.285714                  0.404255   \n",
       "4                      0                 0.142857                  0.606383   \n",
       "\n",
       "   pcm_intensity_sma_minPos  pcm_intensity_sma_amean  \\\n",
       "0                       0.0                        0   \n",
       "1                       0.0                        0   \n",
       "2                       0.0                        0   \n",
       "3                       0.0                        0   \n",
       "4                       0.0                        0   \n",
       "\n",
       "   pcm_intensity_sma_linregc1  ...  F0env_sma_de_linregerrQ  \\\n",
       "0                           0  ...                 0.092117   \n",
       "1                           0  ...                 0.031789   \n",
       "2                           0  ...                 0.097341   \n",
       "3                           0  ...                 0.055432   \n",
       "4                           0  ...                 0.033673   \n",
       "\n",
       "   F0env_sma_de_stddev  F0env_sma_de_skewness  F0env_sma_de_kurtosis  \\\n",
       "0             0.294281               0.771490               0.589508   \n",
       "1             0.203679               0.565664               0.335376   \n",
       "2             0.341096               0.657804               0.451624   \n",
       "3             0.245241               0.516015               0.350308   \n",
       "4             0.199890               0.519454               0.265627   \n",
       "\n",
       "   F0env_sma_de_quartile1  F0env_sma_de_quartile2  F0env_sma_de_quartile3  \\\n",
       "0                0.117983                0.017167                0.027963   \n",
       "1                0.120382                0.027347                0.045084   \n",
       "2                0.107132                0.017167                0.028058   \n",
       "3                0.121571                0.020762                0.048233   \n",
       "4                0.119747                0.022636                0.045822   \n",
       "\n",
       "   F0env_sma_de_iqr12  F0env_sma_de_iqr23  F0env_sma_de_iqr13  \n",
       "0            0.013516            0.067167            2.028063  \n",
       "1            0.044086            0.085771            3.003057  \n",
       "2            0.054392            0.067393            2.663894  \n",
       "3            0.013987            0.107900            3.138976  \n",
       "4            0.028148            0.097964            3.087905  \n",
       "\n",
       "[5 rows x 847 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surprised', 'angry', 'happy'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angry        53.579176\n",
       "happy        36.514823\n",
       "surprised     9.906001\n",
       "Name: Emotion , dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion '].value_counts()/df['Emotion '].shape*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Type', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['name', 'Emotion '], axis = 1) \n",
    "y = df['Emotion ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 415)\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 844\n"
     ]
    }
   ],
   "source": [
    "print(f'Features extracted: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier(alpha = 0.01, batch_size = 256, epsilon = 1e-08, hidden_layer_sizes = (300,), \n",
    "                    learning_rate='adaptive', max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the accuracy of our model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.90%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_train)\n",
    "accuracy = accuracy_score(y_true = y_train, y_pred = y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_classification=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(x_traincnn.shape[1],x_traincnn.shape[2])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))###################################\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(variables_for_classification))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# NEW MODEL ###################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(x_traincnn.shape[1],x_traincnn.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 8, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv1D(64, 8, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 8, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(BatchNormalization())       \n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "# model.add(Conv1D(265, 8, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv1D(128, 8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))      \n",
    "# model.add(BatchNormalization())       \n",
    "# model.add(MaxPooling1D(pool_size=(2)))\n",
    "# model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 844, 256)          1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 844, 256)          1024      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 837, 128)          262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 837, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 418, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 418, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 411, 64)           65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 411, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 404, 64)           32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 404, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 202, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 202, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12928)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              13239296  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 14,129,923\n",
      "Trainable params: 14,128,899\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile your model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 968 samples, validate on 415 samples\n",
      "Epoch 1/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 56.7922 - accuracy: 0.7717 - val_loss: 55.2331 - val_accuracy: 0.3663\n",
      "Epoch 2/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 52.4986 - accuracy: 0.9163 - val_loss: 51.2577 - val_accuracy: 0.4289\n",
      "Epoch 3/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 48.4481 - accuracy: 0.9215 - val_loss: 46.8114 - val_accuracy: 0.7229\n",
      "Epoch 4/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 44.3811 - accuracy: 0.9597 - val_loss: 42.7530 - val_accuracy: 0.8096\n",
      "Epoch 5/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 40.6838 - accuracy: 0.9463 - val_loss: 39.6950 - val_accuracy: 0.5904\n",
      "Epoch 6/350\n",
      "968/968 [==============================] - 29s 29ms/step - loss: 37.0051 - accuracy: 0.9793 - val_loss: 35.4800 - val_accuracy: 0.9133\n",
      "Epoch 7/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 33.6317 - accuracy: 0.9855 - val_loss: 32.2406 - val_accuracy: 0.8892\n",
      "Epoch 8/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 30.5045 - accuracy: 0.9835 - val_loss: 29.2141 - val_accuracy: 0.9373\n",
      "Epoch 9/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 27.6643 - accuracy: 0.9793 - val_loss: 26.4502 - val_accuracy: 0.9494\n",
      "Epoch 10/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 25.0570 - accuracy: 0.9752 - val_loss: 23.9820 - val_accuracy: 0.9470\n",
      "Epoch 11/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 22.6950 - accuracy: 0.9907 - val_loss: 21.7645 - val_accuracy: 0.9494\n",
      "Epoch 12/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 20.5538 - accuracy: 0.9917 - val_loss: 19.7329 - val_accuracy: 0.9566\n",
      "Epoch 13/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 18.6071 - accuracy: 0.9917 - val_loss: 17.9346 - val_accuracy: 0.9470\n",
      "Epoch 14/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 16.8765 - accuracy: 0.9907 - val_loss: 16.2900 - val_accuracy: 0.9277\n",
      "Epoch 15/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 15.3203 - accuracy: 0.9897 - val_loss: 14.7886 - val_accuracy: 0.9494\n",
      "Epoch 16/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 13.9062 - accuracy: 0.9938 - val_loss: 13.4997 - val_accuracy: 0.9470\n",
      "Epoch 17/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 12.6498 - accuracy: 0.9990 - val_loss: 12.3153 - val_accuracy: 0.9518\n",
      "Epoch 18/350\n",
      "968/968 [==============================] - 30s 30ms/step - loss: 11.5710 - accuracy: 0.9845 - val_loss: 11.2062 - val_accuracy: 0.9614\n",
      "Epoch 19/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 10.6086 - accuracy: 0.9866 - val_loss: 10.3452 - val_accuracy: 0.9325\n",
      "Epoch 20/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 9.6947 - accuracy: 0.9948 - val_loss: 9.4525 - val_accuracy: 0.9446\n",
      "Epoch 21/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 8.8943 - accuracy: 0.9897 - val_loss: 8.6783 - val_accuracy: 0.9349\n",
      "Epoch 22/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 8.1541 - accuracy: 0.9948 - val_loss: 7.9673 - val_accuracy: 0.9518\n",
      "Epoch 23/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 7.5001 - accuracy: 0.9907 - val_loss: 7.3394 - val_accuracy: 0.9614\n",
      "Epoch 24/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 6.9042 - accuracy: 0.9938 - val_loss: 6.8121 - val_accuracy: 0.9446\n",
      "Epoch 25/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 6.3737 - accuracy: 0.9938 - val_loss: 6.2987 - val_accuracy: 0.9518\n",
      "Epoch 26/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 5.8926 - accuracy: 0.9917 - val_loss: 5.8724 - val_accuracy: 0.9349\n",
      "Epoch 27/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 5.4501 - accuracy: 0.9886 - val_loss: 5.4797 - val_accuracy: 0.9229\n",
      "Epoch 28/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 5.1057 - accuracy: 0.9793 - val_loss: 5.2297 - val_accuracy: 0.9229\n",
      "Epoch 29/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 4.7769 - accuracy: 0.9773 - val_loss: 4.8072 - val_accuracy: 0.9470\n",
      "Epoch 30/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 4.4224 - accuracy: 0.9897 - val_loss: 4.4572 - val_accuracy: 0.9446\n",
      "Epoch 31/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 4.0956 - accuracy: 0.9928 - val_loss: 4.1709 - val_accuracy: 0.9349\n",
      "Epoch 32/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 3.7864 - accuracy: 0.9969 - val_loss: 3.8318 - val_accuracy: 0.9639\n",
      "Epoch 33/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 3.5188 - accuracy: 0.9959 - val_loss: 3.5750 - val_accuracy: 0.9494\n",
      "Epoch 34/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 3.2600 - accuracy: 0.9959 - val_loss: 3.3089 - val_accuracy: 0.9590\n",
      "Epoch 35/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 3.0114 - accuracy: 0.9979 - val_loss: 3.0756 - val_accuracy: 0.9422\n",
      "Epoch 36/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 2.7884 - accuracy: 0.9969 - val_loss: 2.8948 - val_accuracy: 0.9398\n",
      "Epoch 37/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 2.5965 - accuracy: 0.9938 - val_loss: 2.6568 - val_accuracy: 0.9518\n",
      "Epoch 38/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 2.4398 - accuracy: 0.9886 - val_loss: 2.6298 - val_accuracy: 0.9253\n",
      "Epoch 39/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 2.3000 - accuracy: 0.9845 - val_loss: 2.3597 - val_accuracy: 0.9470\n",
      "Epoch 40/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 2.1450 - accuracy: 0.9928 - val_loss: 2.3045 - val_accuracy: 0.9422\n",
      "Epoch 41/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 2.0073 - accuracy: 0.9948 - val_loss: 2.0840 - val_accuracy: 0.9446\n",
      "Epoch 42/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 1.8870 - accuracy: 0.9876 - val_loss: 2.0191 - val_accuracy: 0.9398\n",
      "Epoch 43/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 1.8388 - accuracy: 0.9773 - val_loss: 1.9117 - val_accuracy: 0.9494\n",
      "Epoch 44/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 1.7219 - accuracy: 0.9866 - val_loss: 1.8109 - val_accuracy: 0.9446\n",
      "Epoch 45/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 1.5766 - accuracy: 0.9917 - val_loss: 1.6593 - val_accuracy: 0.9566\n",
      "Epoch 46/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 1.4711 - accuracy: 0.9917 - val_loss: 1.6052 - val_accuracy: 0.9470\n",
      "Epoch 47/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 1.3906 - accuracy: 0.9845 - val_loss: 1.5381 - val_accuracy: 0.9373\n",
      "Epoch 48/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 1.2901 - accuracy: 0.9897 - val_loss: 1.4087 - val_accuracy: 0.9542\n",
      "Epoch 49/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 1.1890 - accuracy: 0.9948 - val_loss: 1.3073 - val_accuracy: 0.9566\n",
      "Epoch 50/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 1.0907 - accuracy: 0.9959 - val_loss: 1.2136 - val_accuracy: 0.9518\n",
      "Epoch 51/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 1.0008 - accuracy: 0.9969 - val_loss: 1.1099 - val_accuracy: 0.9663\n",
      "Epoch 52/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.9253 - accuracy: 0.9959 - val_loss: 1.0560 - val_accuracy: 0.9590\n",
      "Epoch 53/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.8509 - accuracy: 0.9990 - val_loss: 0.9950 - val_accuracy: 0.9518\n",
      "Epoch 54/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.7854 - accuracy: 0.9979 - val_loss: 0.9107 - val_accuracy: 0.9614\n",
      "Epoch 55/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.7170 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.9566\n",
      "Epoch 56/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968/968 [==============================] - 29s 30ms/step - loss: 0.6636 - accuracy: 0.9979 - val_loss: 0.8555 - val_accuracy: 0.9590\n",
      "Epoch 57/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.6209 - accuracy: 0.9959 - val_loss: 0.8522 - val_accuracy: 0.9229\n",
      "Epoch 58/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.6398 - accuracy: 0.9845 - val_loss: 0.8649 - val_accuracy: 0.9205\n",
      "Epoch 59/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.6902 - accuracy: 0.9773 - val_loss: 0.9365 - val_accuracy: 0.9373\n",
      "Epoch 60/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.6767 - accuracy: 0.9824 - val_loss: 0.8365 - val_accuracy: 0.9398\n",
      "Epoch 61/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.6087 - accuracy: 0.9938 - val_loss: 0.7530 - val_accuracy: 0.9470\n",
      "Epoch 62/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.5690 - accuracy: 0.9917 - val_loss: 0.6775 - val_accuracy: 0.9614\n",
      "Epoch 63/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.5171 - accuracy: 0.9948 - val_loss: 0.6551 - val_accuracy: 0.9566\n",
      "Epoch 64/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.4683 - accuracy: 0.9959 - val_loss: 0.6365 - val_accuracy: 0.9398\n",
      "Epoch 65/350\n",
      "968/968 [==============================] - 31s 32ms/step - loss: 0.4400 - accuracy: 0.9938 - val_loss: 0.5837 - val_accuracy: 0.9446\n",
      "Epoch 66/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.4277 - accuracy: 0.9928 - val_loss: 0.6135 - val_accuracy: 0.9494\n",
      "Epoch 67/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.3818 - accuracy: 0.9990 - val_loss: 0.5395 - val_accuracy: 0.9446\n",
      "Epoch 68/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.3426 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9614\n",
      "Epoch 69/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.3091 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9590\n",
      "Epoch 70/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2813 - accuracy: 0.9990 - val_loss: 0.4340 - val_accuracy: 0.9614\n",
      "Epoch 71/350\n",
      "968/968 [==============================] - 31s 32ms/step - loss: 0.2621 - accuracy: 0.9979 - val_loss: 0.4498 - val_accuracy: 0.9422\n",
      "Epoch 72/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2530 - accuracy: 0.9969 - val_loss: 0.4936 - val_accuracy: 0.9277\n",
      "Epoch 73/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.2887 - accuracy: 0.9897 - val_loss: 0.5727 - val_accuracy: 0.9181\n",
      "Epoch 74/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.3685 - accuracy: 0.9680 - val_loss: 0.7387 - val_accuracy: 0.9181\n",
      "Epoch 75/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.3869 - accuracy: 0.9814 - val_loss: 0.6454 - val_accuracy: 0.9373\n",
      "Epoch 76/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.3847 - accuracy: 0.9876 - val_loss: 0.5896 - val_accuracy: 0.9277\n",
      "Epoch 77/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.3480 - accuracy: 0.9917 - val_loss: 0.5712 - val_accuracy: 0.9518\n",
      "Epoch 78/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.3190 - accuracy: 0.9969 - val_loss: 0.4846 - val_accuracy: 0.9518\n",
      "Epoch 79/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.2742 - accuracy: 0.9979 - val_loss: 0.4563 - val_accuracy: 0.9494\n",
      "Epoch 80/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2435 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9542\n",
      "Epoch 81/350\n",
      "968/968 [==============================] - 31s 32ms/step - loss: 0.2181 - accuracy: 0.9990 - val_loss: 0.3948 - val_accuracy: 0.9518\n",
      "Epoch 82/350\n",
      "968/968 [==============================] - 31s 32ms/step - loss: 0.1981 - accuracy: 0.9990 - val_loss: 0.3425 - val_accuracy: 0.9590\n",
      "Epoch 83/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.1829 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9566\n",
      "Epoch 84/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.1672 - accuracy: 0.9990 - val_loss: 0.3119 - val_accuracy: 0.9542\n",
      "Epoch 85/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.1532 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9542\n",
      "Epoch 86/350\n",
      "968/968 [==============================] - 29s 29ms/step - loss: 0.1396 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9470\n",
      "Epoch 87/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9542\n",
      "Epoch 88/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.1216 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9494\n",
      "Epoch 89/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9398\n",
      "Epoch 90/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.1181 - accuracy: 0.9990 - val_loss: 0.2759 - val_accuracy: 0.9566\n",
      "Epoch 91/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.1334 - accuracy: 0.9938 - val_loss: 0.4027 - val_accuracy: 0.9253\n",
      "Epoch 92/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.2936 - accuracy: 0.9587 - val_loss: 0.9393 - val_accuracy: 0.8867\n",
      "Epoch 93/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.3504 - accuracy: 0.9721 - val_loss: 0.7388 - val_accuracy: 0.9060\n",
      "Epoch 94/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.2906 - accuracy: 0.9959 - val_loss: 0.4719 - val_accuracy: 0.9349\n",
      "Epoch 95/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.2406 - accuracy: 0.9948 - val_loss: 0.4391 - val_accuracy: 0.9398\n",
      "Epoch 96/350\n",
      "968/968 [==============================] - 28s 29ms/step - loss: 0.2101 - accuracy: 0.9979 - val_loss: 0.3984 - val_accuracy: 0.9518\n",
      "Epoch 97/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.1883 - accuracy: 0.9969 - val_loss: 0.3816 - val_accuracy: 0.9590\n",
      "Epoch 98/350\n",
      "968/968 [==============================] - 31s 32ms/step - loss: 0.1635 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9518\n",
      "Epoch 99/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9518\n",
      "Epoch 100/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1287 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9542\n",
      "Epoch 101/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1175 - accuracy: 0.9990 - val_loss: 0.3237 - val_accuracy: 0.9398\n",
      "Epoch 102/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1104 - accuracy: 0.9990 - val_loss: 0.2689 - val_accuracy: 0.9566\n",
      "Epoch 103/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9566\n",
      "Epoch 104/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9494\n",
      "Epoch 105/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9639\n",
      "Epoch 106/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9470\n",
      "Epoch 107/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9590\n",
      "Epoch 108/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9639\n",
      "Epoch 109/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.0916 - accuracy: 0.9969 - val_loss: 0.3431 - val_accuracy: 0.9277\n",
      "Epoch 110/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1914 - accuracy: 0.9700 - val_loss: 1.2282 - val_accuracy: 0.8771\n",
      "Epoch 111/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.3658 - accuracy: 0.9483 - val_loss: 0.6955 - val_accuracy: 0.9325\n",
      "Epoch 112/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2930 - accuracy: 0.9855 - val_loss: 0.4440 - val_accuracy: 0.9470\n",
      "Epoch 113/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2438 - accuracy: 0.9928 - val_loss: 0.4692 - val_accuracy: 0.9349\n",
      "Epoch 114/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2063 - accuracy: 0.9969 - val_loss: 0.4176 - val_accuracy: 0.9349\n",
      "Epoch 115/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1779 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9542\n",
      "Epoch 116/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1580 - accuracy: 0.9979 - val_loss: 0.3367 - val_accuracy: 0.9494\n",
      "Epoch 117/350\n",
      "968/968 [==============================] - 31s 32ms/step - loss: 0.1440 - accuracy: 0.9990 - val_loss: 0.3241 - val_accuracy: 0.9518\n",
      "Epoch 118/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1321 - accuracy: 0.9990 - val_loss: 0.3734 - val_accuracy: 0.9325\n",
      "Epoch 119/350\n",
      "968/968 [==============================] - 29s 30ms/step - loss: 0.1208 - accuracy: 0.9990 - val_loss: 0.3436 - val_accuracy: 0.9398\n",
      "Epoch 120/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1188 - accuracy: 0.9959 - val_loss: 0.3404 - val_accuracy: 0.9301\n",
      "Epoch 121/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1368 - accuracy: 0.9917 - val_loss: 0.3506 - val_accuracy: 0.9446\n",
      "Epoch 122/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1602 - accuracy: 0.9886 - val_loss: 0.3736 - val_accuracy: 0.9518\n",
      "Epoch 123/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2168 - accuracy: 0.9804 - val_loss: 0.5513 - val_accuracy: 0.9349\n",
      "Epoch 124/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2151 - accuracy: 0.9917 - val_loss: 0.4349 - val_accuracy: 0.9349\n",
      "Epoch 125/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.2016 - accuracy: 0.9876 - val_loss: 0.3584 - val_accuracy: 0.9470\n",
      "Epoch 126/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1807 - accuracy: 0.9979 - val_loss: 0.3881 - val_accuracy: 0.9494\n",
      "Epoch 127/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1565 - accuracy: 0.9979 - val_loss: 0.3605 - val_accuracy: 0.9518\n",
      "Epoch 128/350\n",
      "968/968 [==============================] - 30s 31ms/step - loss: 0.1454 - accuracy: 0.9938 - val_loss: 0.3096 - val_accuracy: 0.9494\n",
      "Epoch 00128: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Training\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.0001)\n",
    "mcp_save = ModelCheckpoint('model/Ar_model_CNN_2.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=350,\n",
    "                     validation_data=(x_testcnn, y_test), callbacks=[mcp_save, lr_reduce, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Train Valid Loss Graph\n",
    "\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model.json\n",
    "\n",
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"Ar1_model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 96.39%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('Ar1_model2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model/Ar_model_CNN_2.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99380165\n"
     ]
    }
   ],
   "source": [
    "print(cnnhistory.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9493975639343262\n"
     ]
    }
   ],
   "source": [
    "print(cnnhistory.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1454281720740736\n",
      "0.30960080896515446\n"
     ]
    }
   ],
   "source": [
    "print(cnnhistory.history['loss'][-1])\n",
    "print(cnnhistory.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415/415 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictedvalues\n",
       "0           angry\n",
       "1           angry\n",
       "2           angry\n",
       "3           happy\n",
       "4       surprised\n",
       "5           angry\n",
       "6           angry\n",
       "7           happy\n",
       "8           happy\n",
       "9           happy"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actualvalues\n",
       "0        angry\n",
       "1        angry\n",
       "2        angry\n",
       "3        happy\n",
       "4    surprised\n",
       "5        angry\n",
       "6        angry\n",
       "7        happy\n",
       "8        happy\n",
       "9        happy"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    actualvalues predictedvalues\n",
       "0          angry           angry\n",
       "1          angry           angry\n",
       "2          angry           angry\n",
       "3          happy           happy\n",
       "4      surprised       surprised\n",
       "..           ...             ...\n",
       "410        happy           angry\n",
       "411        angry           angry\n",
       "412        angry           angry\n",
       "413        angry           angry\n",
       "414        angry           angry\n",
       "\n",
       "[415 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     400\n",
       "False     15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(finaldf.actualvalues == finaldf.predictedvalues).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>angry</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>surprised</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>angry</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>surprised</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>happy</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>surprised</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>happy</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>happy</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>happy</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actualvalues predictedvalues\n",
       "99         angry       surprised\n",
       "117    surprised           happy\n",
       "125        angry       surprised\n",
       "135    surprised           angry\n",
       "143        happy           angry\n",
       "172        angry           happy\n",
       "193        happy           angry\n",
       "203        happy       surprised\n",
       "251    surprised           happy\n",
       "257        happy       surprised\n",
       "269        happy           angry\n",
       "317        happy       surprised\n",
       "352        angry           happy\n",
       "356        happy       surprised\n",
       "410        happy           angry"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf[finaldf.actualvalues != finaldf.predictedvalues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Nueral Nertwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) # activation for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(X_train.shape[1],\n",
    "                input_dim=X_train.shape[1],\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(0.01)))\n",
    "model_1.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = model_1.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=1000,\n",
    "                    batch_size=None,\n",
    "                    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = result.history['loss']\n",
    "test_loss = result.history['val_loss']\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Testing loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss1 = result_1.history['loss']\n",
    "test_loss1 = result_1.history['val_loss']\n",
    "plt.plot(train_loss1, label='Training loss')\n",
    "plt.plot(test_loss1, label='Testing loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Accuracy', result_1.history['loss'][-1])\n",
    "print('Test Accuracy', result_1.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(X_train.shape[1],\n",
    "                input_dim=X_train.shape[1],\n",
    "                activation='relu'))\n",
    "model_2.add(Dropout(0.8))\n",
    "model_2.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = model_2.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=450,\n",
    "                    batch_size=None,\n",
    "                    verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train loss', result_2.history['loss'][-1])\n",
    "print('Test loss', result_2.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot loss function\n",
    "train_loss = result_2.history['loss']\n",
    "test_loss = result_2.history['val_loss']\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Testing loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
